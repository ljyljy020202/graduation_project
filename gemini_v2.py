import os
import json
from common.prompt_loader import load_prompt
from common.file_utils import load_json, save_json
from common.llm_client import GeminiClient
from common.response_parser import safe_parse_response_json

PROMPT_PATH = "./prompts/labeling_prompt.txt"
INPUT_ROOT = "./Simple_DataSet"
OUTPUT_ROOT = "./results/gemini"

system_prompt = load_prompt(PROMPT_PATH)
llm = GeminiClient()

# âœ… ëª¨ë“  í•˜ìœ„ í´ë” ìˆœíšŒ (ê³„ì¸µ êµ¬ì¡° ëŒ€ì‘)
for root, dirs, files in os.walk(INPUT_ROOT):
    for filename in files:
        if not filename.endswith(".json"):
            continue

        input_path = os.path.join(root, filename)

        # ì…ë ¥ êµ¬ì¡° ê·¸ëŒ€ë¡œ ì¶œë ¥ì— ë°˜ì˜
        relative_path = os.path.relpath(input_path, INPUT_ROOT)
        output_path = os.path.join(OUTPUT_ROOT, relative_path)

        # ì¶œë ¥ í´ë” ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if os.path.exists(output_path):
            print(f"â© Skipping (already exists): {output_path}")
            continue

        print(f"ğŸ” Processing: {relative_path}")

        input_json = load_json(input_path)

        result_text = llm.generate(
            system_prompt=system_prompt,
            user_content=json.dumps(input_json, ensure_ascii=False)
        )

        # âœ… ì•ˆì „í•œ JSON íŒŒì‹±
        result_json = safe_parse_response_json(result_text, relative_path)

        save_json(output_path, result_json)
        print(f"âœ… Gemini Saved: {output_path}")